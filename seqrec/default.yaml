num_proc: 1
cache_dir: seqrec/cache/       # Usually for raw and processed data
log_dir: seqrec/logs/
tensorboard_log_dir: seqrec/tensorboard/
ckpt_dir: seqrec/ckpt/
rand_seed: 2024
reproducibility: True

max_seq_length: 10
whiten: False

train_batch_size: 256
eval_batch_size: 32
lr: 1.0e-3
weight_decay: 1.0e-4
warmup_steps: 10000
steps: ~
# epochs: 150
epochs: 1000

max_grad_norm: 1.0      # None for no clipping, else a float value
eval_interval: 5        # Evaluate every n epochs
patience: 20            # Early stopping. Stop training after n epochs without improvement. Set to None to disable

topk: [5,10,20]
metrics: [ndcg,recall]
val_metric: recall@20
run_id: Eval  # Change this to your customized run id


save: True